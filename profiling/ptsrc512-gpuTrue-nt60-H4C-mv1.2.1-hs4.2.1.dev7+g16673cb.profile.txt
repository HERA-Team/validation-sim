Timer unit: 1e-09 s

Total time: 239.938 s
File: /jet/home/sgm/miniconda3/envs/h6c/lib/python3.10/site-packages/hera_sim/visibilities/cli.py
Function: run_vis_sim at line 88

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    88                                           def run_vis_sim(args):
    89         1    1749555.0    2e+06      0.0      cprint(Panel("hera-sim-vis: Simulating Visibilities"))
    90                                           
    91         1    4081372.0    4e+06      0.0      logger.info("Initializing VisibilitySimulator object... ")
    92         1    9819722.0    1e+07      0.0      simulator = load_simulator_from_yaml(args.simulator_config)
    93         1    4078262.0    4e+06      0.0      logger.info("Finished VisibilitySimulator Init")
    94                                           
    95                                               # Make data_model, simulator, and simulation objects
    96         1    4001482.0    4e+06      0.0      logger.info("Initializing ModelData object... ")
    97         2        3e+10    2e+10     13.2      data_model = ModelData.from_config(
    98         1       1794.0   1794.0      0.0          args.obsparam, normalize_beams=args.normalize_beams
    99                                               )
   100         1    4634368.0    5e+06      0.0      logger.info("Finished Setting up ModelData object")
   101         1   32043005.0    3e+07      0.0      print_sim_config(args.obsparam)
   102                                           
   103         1     802072.0 802072.0      0.0      cprint(f"Using {simulator.__class__.__name__} Simulator")
   104                                           
   105                                               # Print versions
   106         2    4017766.0    2e+06      0.0      cprint(
   107         7       7350.0   1050.0      0.0          f"""
   108                                           [bold]Using the following packages:[/bold]
   109                                           
   110         1       7958.0   7958.0      0.0  \tpyuvdata: {pyuvdata.__version__}
   111         1       4762.0   4762.0      0.0  \tpyuvsim: {pyuvsim.__version__}
   112         1       1318.0   1318.0      0.0  \tpyradiosky: {pyradiosky.__version__}
   113         1       3164.0   3164.0      0.0  \thera_sim: {hera_sim.__version__}
   114         2       3895.0   1947.5      0.0  \t{simulator.__class__.__name__}: {simulator.__version__}
   115                                           """
   116                                               )
   117                                           
   118         1    2524802.0    3e+06      0.0      cns.print(Rule("Important Simulation Parameters"))
   119         1     862389.0 862389.0      0.0      cns.print(f"Nfreqs  : {data_model.uvdata.Nfreqs}")
   120         1   22986969.0    2e+07      0.0      cns.print(f"Ntimes  : {len(data_model.lsts)}")
   121         1     911922.0 911922.0      0.0      cns.print(f"Npols   : {data_model.uvdata.Npols}")
   122         1     809386.0 809386.0      0.0      cns.print(f"Nants   : {data_model.uvdata.Nants_data}")
   123         1     801220.0 801220.0      0.0      cns.print(f"Nsources: {data_model.sky_model.Ncomponents}")
   124         1     808849.0 808849.0      0.0      cns.print(f"Nbeams  : {data_model.n_beams}")
   125         1     387978.0 387978.0      0.0      cns.print()
   126                                           
   127         1    2399414.0    2e+06      0.0      cns.print(Rule("Large Memory Components"))
   128         2     934154.0 467077.0      0.0      cns.print(
   129         1      24228.0  24228.0      0.0          f"Visibility Array  : {data_model.uvdata.data_array.nbytes / 1024**2:.2f} MB"
   130                                               )
   131         2      16982.0   8491.0      0.0      beam_array_sizes = [
   132         1        646.0    646.0      0.0          b.data_array.nbytes for b in data_model.beams if hasattr(b, "data_array")
   133                                               ]
   134         1        337.0    337.0      0.0      if beam_array_sizes:
   135         1     936748.0 936748.0      0.0          cns.print(f"Largest Beam Array: {max(beam_array_sizes) / 1024**2:.2f} MB")
   136         1     944046.0 944046.0      0.0          cns.print(f"Total Beam Arrays : {sum(beam_array_sizes) / 1024**2:.2f} MB")
   137                                           
   138         1   63884145.0    6e+07      0.0      ram = simulator.estimate_memory(data_model)
   139         1     355105.0 355105.0      0.0      ram_avail = psutil.virtual_memory().available / 1024**3
   140                                           
   141         2    1933862.0 966931.0      0.0      cprint(
   142         3      10168.0   3389.3      0.0          f"[bold {'red' if ram < 1.5*ram_avail else 'green'}] This simulation will use "
   143         2        734.0    367.0      0.0          f"at least {ram:.2f}GB of RAM (Available: {ram_avail:.2f}GB).[/]"
   144                                               )
   145                                           
   146         1       7352.0   7352.0      0.0      if args.object_name is None:
   147         1      58081.0  58081.0      0.0          data_model.uvdata.object_name = simulator.__class__.__name__
   148                                               else:
   149                                                   data_model.uvdata.object_name = args.object_name
   150                                           
   151         1       1048.0   1048.0      0.0      if args.dry_run:
   152                                                   cprint("Dry run finished.")
   153                                                   return
   154                                           
   155         1  148735961.0    1e+08      0.1      simulation = VisibilitySimulation(data_model=data_model, simulator=simulator)
   156                                           
   157                                               # Run simulation
   158         1     467712.0 467712.0      0.0      cprint()
   159         1    2695239.0    3e+06      0.0      cprint(Rule("Running Simulation"))
   160         1    3994216.0    4e+06      0.0      logger.info("About to Run Simulation")
   161         1        2e+11    2e+11     83.4      simulation.simulate()
   162         1    4020256.0    4e+06      0.0      logger.info("Simulation Complete")
   163         1    1148023.0    1e+06      0.0      cprint(Rule())
   164                                           
   165         1        755.0    755.0      0.0      if myid != 0:  # pragma: no cover
   166                                                   # Wait for root worker to finish IO before ending all other worker procs
   167                                                   comm.Barrier()
   168                                                   sys.exit(0)
   169                                           
   170         1       6740.0   6740.0      0.0      if args.run_auto_check:
   171                                                   # Check imaginary of xx/yy autos and fix non-real values if the option is
   172                                                   # selected in the arguments
   173                                                   # xxpol = data_model.uvdata.get_data("xx")
   174                                                   # auto_idx = data_model.uvdata.ant_1_array == data_model.uvdata.ant_2_array
   175                                                   # xxpol = xxpol[auto_idx]
   176                                           
   177                                                   # max_xx_autos_to_abs = (np.abs(xxpol.imag) / np.abs(xxpol)).max()
   178                                           
   179                                                   uvd_autos = data_model.uvdata.select(
   180                                                       ant_str="auto",
   181                                                       inplace=False,
   182                                                       run_check=False,
   183                                                       run_check_acceptability=False,
   184                                                       check_extra=False,
   185                                                   )
   186                                                   xx = uvd_autos.get_data("xx")
   187                                                   max_xx_autos_to_abs = (np.abs(xx.imag) / np.abs(xx)).max()
   188                                                   if 0 < max_xx_autos_to_abs < args.max_auto_imag:
   189                                                       logger.warning(
   190                                                           f"[orange]Some autos have very small imaginary components (max ratio "
   191                                                           f"[blue]{max_xx_autos_to_abs:1.2e}[/])"
   192                                                       )
   193                                           
   194                                                       if args.fix_autos:
   195                                                           logger.info("Setting the autos to be purely real... ")
   196                                                           data_model.uvdata._fix_autos()
   197                                                           logger.info("Done fixing autos.")
   198                                           
   199                                                   elif max_xx_autos_to_abs >= args.max_auto_imag:
   200                                                       raise ValueError(
   201                                                           f"Some autos have large fractional imaginary components "
   202                                                           f"(>{args.max_auto_imag:1.2e}). Largest value = "
   203                                                           f"{np.abs(xx.imag).max():1.2e}, largest fraction="
   204                                                           f"{max_xx_autos_to_abs:1.2e}."
   205                                                       )
   206                                           
   207         1        679.0    679.0      0.0      if args.compress:
   208         1    3708602.0    4e+06      0.0          logger.info("Compressing data by redundancy... ")
   209                                                   # Here, we don't call the convenience function directly, because we want to
   210                                                   # be able to short-circuit the process by reading in a file.
   211         1     453378.0 453378.0      0.0          if not Path(args.compress).exists():
   212         3 2271200641.0    8e+08      0.9              red_gps = data_model.uvdata.get_redundancies(
   213         1        332.0    332.0      0.0                  tol=1.0, include_conjugates=True
   214         1        584.0    584.0      0.0              )[0]
   215         1   40622449.0    4e+07      0.0              bl_ants = [data_model.uvdata.baseline_to_antnums(gp[0]) for gp in red_gps]
   216         3 5217477184.0    2e+09      2.2              blt_inds = data_model.uvdata._select_preprocess(
   217         1        269.0    269.0      0.0                  antenna_nums=None,
   218         1        309.0    309.0      0.0                  antenna_names=None,
   219         1        300.0    300.0      0.0                  ant_str=None,
   220         1        171.0    171.0      0.0                  bls=bl_ants,
   221         1        223.0    223.0      0.0                  frequencies=None,
   222         1        329.0    329.0      0.0                  freq_chans=None,
   223         1        319.0    319.0      0.0                  times=None,
   224         1        671.0    671.0      0.0                  time_range=None,
   225         1        253.0    253.0      0.0                  lsts=None,
   226         1        228.0    228.0      0.0                  lst_range=None,
   227         1        286.0    286.0      0.0                  polarizations=None,
   228         1        214.0    214.0      0.0                  blt_inds=None,
   229         1        331.0    331.0      0.0                  phase_center_ids=None,
   230         1        150.0    150.0      0.0                  catalog_names=None,
   231         1        712.0    712.0      0.0              )[0]
   232                                           
   233         1   16582752.0    2e+07      0.0              np.save(args.compress, blt_inds)
   234                                                   else:
   235                                                       blt_inds = np.load(args.compress)
   236                                           
   237         2  240147344.0    1e+08      0.1          data_model.uvdata._select_by_index(
   238         1        551.0    551.0      0.0              blt_inds, None, None, "Compressed by redundancy", keep_all_metadata=True
   239                                                   )
   240                                           
   241         1    3863946.0    4e+06      0.0          logger.info("Done with compression.")
   242                                           
   243                                               # Read obsparams to get filing config
   244         2     554263.0 277131.5      0.0      with open(args.obsparam) as file:
   245         1   10758431.0    1e+07      0.0          obsparam_dict = yaml.safe_load(file)
   246         1       3388.0   3388.0      0.0      cfg_filing = obsparam_dict["filing"]
   247         1      61409.0  61409.0      0.0      base_path = Path(cfg_filing["outdir"])
   248         1     569875.0 569875.0      0.0      base_path.mkdir(parents=True, exist_ok=True)
   249         1     111867.0 111867.0      0.0      outfile = base_path / f"{cfg_filing['outfile_name']}.{cfg_filing['output_format']}"
   250         1       5300.0   5300.0      0.0      clobber = cfg_filing.get("clobber", False)
   251                                           
   252                                               # Write output
   253         1    3826752.0    4e+06      0.0      logger.info("Writing output... ")
   254         2  138539686.0    7e+07      0.1      data_model.uvdata.write_uvh5(
   255         1      23445.0  23445.0      0.0          outfile.as_posix(),
   256         1        188.0    188.0      0.0          clobber=clobber,
   257         1        237.0    237.0      0.0          run_check=False,
   258         1        153.0    153.0      0.0          run_check_acceptability=False,
   259                                               )
   260         1    4055238.0    4e+06      0.0      logger.info("Done Writing.")
   261                                           
   262                                               # Sync with other workers and finalise
   263         1        838.0    838.0      0.0      if HAVE_MPI:
   264                                                   comm.Barrier()
   265                                           
   266         1    1050385.0    1e+06      0.0      cprint("[green][bold]Complete![/][/]")

Total time: 194.017 s
File: /jet/home/sgm/miniconda3/envs/h6c/lib/python3.10/site-packages/matvis/gpu.py
Function: simulate at line 99

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    99                                           @profile
   100                                           def simulate(
   101                                               *,
   102                                               antpos: np.ndarray,
   103                                               freq: float,
   104                                               eq2tops: np.ndarray,
   105                                               crd_eq: np.ndarray,
   106                                               I_sky: np.ndarray,
   107                                               beam_list: Sequence[UVBeam | Callable] | None,
   108                                               polarized: bool = False,
   109                                               beam_idx: np.ndarray | None = None,
   110                                               nthreads: int = 1024,
   111                                               max_memory: int = 2**29,
   112                                               min_chunks: int = 1,
   113                                               precision: int = 1,
   114                                               beam_spline_opts: dict | None = None,
   115                                           ) -> np.ndarray:
   116                                               """GPU implementation of the visibility simulator."""
   117         1       4218.0   4218.0      0.0      if not HAVE_CUDA:
   118                                                   raise ImportError("You need to install the [gpu] extra to use this function!")
   119                                           
   120         1     530464.0 530464.0      0.0      pr = psutil.Process()
   121         2      20228.0  10114.0      0.0      nax, nfeed, nant, ntimes = _validate_inputs(
   122         1        353.0    353.0      0.0          precision, polarized, antpos, eq2tops, crd_eq, I_sky
   123                                               )
   124                                           
   125         1        564.0    564.0      0.0      if beam_spline_opts:
   126         2     203841.0 101920.5      0.0          warnings.warn(
   127         1       1699.0   1699.0      0.0              "You have passed beam_spline_opts, but these are not used in GPU.",
   128         1        162.0    162.0      0.0              stacklevel=1,
   129                                                   )
   130                                           
   131         1       1588.0   1588.0      0.0      nsrc = len(I_sky)
   132                                           
   133         1        391.0    391.0      0.0      if precision == 1:
   134                                                   real_dtype, complex_dtype = np.float32, np.complex64
   135                                                   cublas_real_mm = cublasSgemm
   136                                                   cublas_complex_mm = cublasCgemm
   137                                               else:
   138         1       2738.0   2738.0      0.0          real_dtype, complex_dtype = np.float64, np.complex128
   139         1       2617.0   2617.0      0.0          cublas_real_mm = cublasDgemm
   140         1       1139.0   1139.0      0.0          cublas_complex_mm = cublasZgemm
   141                                           
   142         1       1392.0   1392.0      0.0      DTYPE, CDTYPE = TYPE_MAP[real_dtype], TYPE_MAP[complex_dtype]
   143                                           
   144                                               # apply scalars so 1j*tau*freq is the correct exponent
   145         1       4524.0   4524.0      0.0      ang_freq = 2 * freq * np.pi
   146                                           
   147                                               # ensure data types
   148         1      13366.0  13366.0      0.0      antpos = antpos.astype(real_dtype)
   149         1       8113.0   8113.0      0.0      eq2tops = eq2tops.astype(real_dtype)
   150         1   16442136.0    2e+07      0.0      crd_eq = crd_eq.astype(real_dtype)
   151         1   14309515.0    1e+07      0.0      Isqrt = np.sqrt(0.5 * I_sky).astype(real_dtype)
   152                                           
   153         2  526988050.0    3e+08      0.3      beam_list, nbeam, beam_idx = _wrangle_beams(
   154         1        575.0    575.0      0.0          beam_idx=beam_idx,
   155         1        916.0    916.0      0.0          beam_list=beam_list,
   156         1        353.0    353.0      0.0          polarized=polarized,
   157         1       1346.0   1346.0      0.0          nant=nant,
   158         1        302.0    302.0      0.0          freq=freq,
   159                                               )
   160                                           
   161         2      18963.0   9481.5      0.0      total_beam_pix = sum(
   162                                                   beam.data_array.shape[-2] * beam.data_array.shape[-1]
   163         1        245.0    245.0      0.0          for beam in beam_list
   164                                                   if hasattr(beam, "data_array")
   165                                               )
   166                                           
   167         2       2195.0   1097.5      0.0      nchunks = min(
   168         2       2603.0   1301.5      0.0          max(
   169         1        258.0    258.0      0.0              min_chunks,
   170         2    5994400.0    3e+06      0.0              _get_required_chunks(
   171         1        429.0    429.0      0.0                  nax, nfeed, nant, nsrc, nbeam, total_beam_pix, precision
   172                                                       ),
   173                                                   ),
   174         1        294.0    294.0      0.0          nsrc,
   175                                               )
   176                                           
   177         1        977.0    977.0      0.0      npixc = nsrc // nchunks
   178                                           
   179         1       1853.0   1853.0      0.0      use_uvbeam = isinstance(beam_list[0], UVBeam)
   180         1       5471.0   5471.0      0.0      if use_uvbeam and not all(isinstance(b, UVBeam) for b in beam_list):
   181                                                   raise ValueError(
   182                                                       "gpu.simulate only support beam_lists with either all UVBeam or all AnalyticBeam objects."
   183                                                   )
   184                                           
   185         1       7987.0   7987.0      0.0      cuda_params = {
   186         1        216.0    216.0      0.0          "NANT": nant,
   187         1        173.0    173.0      0.0          "NAX": nax,
   188         1        257.0    257.0      0.0          "NFEED": nfeed,
   189         1        161.0    161.0      0.0          "NBEAM": nbeam,
   190         1        329.0    329.0      0.0          "DTYPE": DTYPE,
   191         1        342.0    342.0      0.0          "CDTYPE": CDTYPE,
   192         1        355.0    355.0      0.0          "f": "f" if precision == 1 else "",
   193                                               }
   194                                           
   195         1        311.0    311.0      0.0      if use_uvbeam:
   196                                                   # We need to make sure that each beam "raw" data is on the same grid.
   197                                                   # There is no advantage to using any other resolution but the native raw
   198                                                   # resolution, which is what is returned by default. This may not be the case
   199                                                   # if we were to use higher-order splines in the initial interpolation from
   200                                                   # UVBeam. Eg. if "cubic" interpolation was shown to be better than linear,
   201                                                   # we might want to do cubic interpolation with pyuvbeam onto a much higher-res
   202                                                   # grid, then use linear interpolation on the GPU with that high-res grid.
   203                                                   # We can explore this later...
   204         1    2700393.0    3e+06      0.0          d0, daz, dza = uvbeam_to_azza_grid(beam_list[0])
   205         1       8932.0   8932.0      0.0          naz = 2 * np.pi / daz + 1
   206         1     225235.0 225235.0      0.0          assert np.isclose(int(naz), naz)
   207                                           
   208         1       1394.0   1394.0      0.0          raw_beam_data = [d0]
   209         1       1431.0   1431.0      0.0          if len(beam_list) > 1:
   210                                                       raw_beam_data.extend(
   211                                                           uvbeam_to_azza_grid(b, naz=int(naz), dza=dza)[0] for b in beam_list[1:]
   212                                                       )
   213                                               else:
   214                                                   daz, dza = None, None
   215                                           
   216                                               # Setup the GPU code and arrays
   217         1     331637.0 331637.0      0.0      meas_eq_code = MeasEqTemplate.render(**cuda_params)
   218                                           
   219         1        383.0    383.0      0.0      if use_uvbeam:
   220         2     250204.0 125102.0      0.0          beam_interp_code = BeamInterpTemplate.render(
   221         3       4048.0   1349.3      0.0              **{
   222         1        209.0    209.0      0.0                  **cuda_params,
   223         1       2754.0   2754.0      0.0                  **{
   224         1        405.0    405.0      0.0                      "NBEAM": nbeam,
   225         1       2612.0   2612.0      0.0                      "BEAM_N_AZ": raw_beam_data[0].shape[-1],
   226         1       1814.0   1814.0      0.0                      "BEAM_N_ZA": raw_beam_data[0].shape[-2],
   227         1        268.0    268.0      0.0                      "DAZ": daz,
   228         1        233.0    233.0      0.0                      "DZA": dza,
   229                                                           },
   230                                                       }
   231                                                   )
   232         1  315683059.0    3e+08      0.2          beam_interp_module = compiler.SourceModule(beam_interp_code)
   233         1     238516.0 238516.0      0.0          beam_interp = beam_interp_module.get_function("InterpolateBeamAltAz")
   234                                               else:
   235                                                   beam_interp = None
   236                                           
   237         1  217401308.0    2e+08      0.1      meas_eq_module = compiler.SourceModule(meas_eq_code)
   238         1      74020.0  74020.0      0.0      meas_eq = meas_eq_module.get_function("MeasEq")
   239                                               # vis_inner_product = meas_eq_module.get_function("VisInnerProduct")
   240                                           
   241         2    7536763.0    4e+06      0.0      logger.info(
   242         5      12361.0   2472.2      0.0          f"""
   243                                                   Measurement Equation Kernel Properties:
   244         1      45102.0  45102.0      0.0              SHARED: {meas_eq.shared_size_bytes}
   245         1       9499.0   9499.0      0.0              LOCAL: {meas_eq.local_size_bytes}
   246         1       9316.0   9316.0      0.0              REGISTERS: {meas_eq.num_regs}
   247         1      11272.0  11272.0      0.0              MAX_THREADS_PER_BLOCK: {meas_eq.max_threads_per_block}
   248                                                   """
   249                                               )
   250                                           
   251                                               # bm_texref = gpu_module.get_texref("bm_tex")
   252         1    3058217.0    3e+06      0.0      h = cublasCreate()  # handle for managing cublas
   253                                           
   254                                               # define GPU buffers and transfer initial values
   255                                               # never changes, transpose happens in copy so cuda bm_tex is (BEAM_PX,BEAM_PX,NANT)
   256                                               # bm_texref.set_array(numpy3d_to_array(beams))
   257         1     561536.0 561536.0      0.0      antpos_gpu = gpuarray.to_gpu(antpos)  # never changes, set to -2*pi*antpos/c
   258         1     212535.0 212535.0      0.0      beam_idx = gpuarray.to_gpu(beam_idx.astype(np.uint))
   259         1     510956.0 510956.0      0.0      Isqrt_gpu = gpuarray.empty(shape=(npixc,), dtype=real_dtype)
   260                                           
   261                                               # Send the regular-grid beam data to the GPU. This has dimensions (Nbeam, Nax, Nfeed, Nza, Nza)
   262                                               # Note that Nbeam is not in general equal to Nant (we can have multiple antennas with
   263                                               # the same beam).
   264         1        556.0    556.0      0.0      if use_uvbeam:
   265         2    1871371.0 935685.5      0.0          beam_data_gpu = gpuarray.to_gpu(
   266         1    1273605.0    1e+06      0.0              np.array(raw_beam_data, dtype=complex_dtype if polarized else real_dtype),
   267                                                   )
   268                                               else:
   269                                                   beam_data_gpu = None
   270                                           
   271                                               # will be set on GPU by bm_interp
   272         1     672121.0 672121.0      0.0      crd_eq_gpu = gpuarray.empty(shape=(3, npixc), dtype=real_dtype)
   273                                               # sent from CPU each time
   274         1      74925.0  74925.0      0.0      eq2top_gpu = gpuarray.empty(shape=(3, 3), dtype=real_dtype)
   275                                               # will be set on GPU
   276         1     363037.0 363037.0      0.0      crdtop_gpu = gpuarray.empty(shape=(3, npixc), dtype=real_dtype)
   277                                               # will be set on GPU
   278         2     112268.0  56134.0      0.0      matvis_gpus = [
   279                                                   gpuarray.empty(shape=(nfeed * nant, nfeed * nant), dtype=complex_dtype)
   280         1       3992.0   3992.0      0.0          for _ in range(nchunks)
   281                                               ]
   282                                           
   283                                               # output CPU buffers for downloading answers
   284         2     160314.0  80157.0      0.0      matvis_cpus = [
   285                                                   np.zeros(shape=(nfeed * nant, nfeed * nant), dtype=complex_dtype)
   286         1       1293.0   1293.0      0.0          for _ in range(nchunks)
   287                                               ]
   288         1      95074.0  95074.0      0.0      streams = [driver.Stream() for _ in range(nchunks)]
   289         1       5164.0   5164.0      0.0      event_order = [
   290                                                   "start",
   291                                                   "upload",
   292                                                   "eq2top",
   293                                                   "tau",
   294                                                   "meas_eq",
   295                                                   "vis",
   296                                                   "end",
   297                                               ]
   298                                           
   299         1        428.0    428.0      0.0      if use_uvbeam:
   300         1       2659.0   2659.0      0.0          event_order.insert(4, "interpolation")
   301                                           
   302         1   73880417.0    7e+07      0.0      vis = np.full((ntimes, nfeed * nant, nfeed * nant), 0.0, dtype=complex_dtype)
   303                                           
   304         1    4529010.0    5e+06      0.0      logger.info(f"Running With {nchunks} chunks")
   305                                           
   306         1       1121.0   1121.0      0.0      report_chunk = ntimes // 100 + 1
   307         1     213073.0 213073.0      0.0      pr = psutil.Process()
   308         1       2497.0   2497.0      0.0      tstart = time.time()
   309         1      95640.0  95640.0      0.0      mlast = pr.memory_info().rss
   310         1        468.0    468.0      0.0      plast = tstart
   311                                           
   312       289     393894.0   1363.0      0.0      for t in range(ntimes):
   313       288   42721461.0 148338.4      0.0          eq2top_gpu.set(eq2tops[t])  # defines sky orientation for this time step
   314       288   21665946.0  75229.0      0.0          events = [{e: driver.Event() for e in event_order} for _ in range(nchunks)]
   315                                           
   316       576    8192574.0  14223.2      0.0          for c, (stream, event) in enumerate(zip(streams, events)):
   317       288    2622270.0   9105.1      0.0              event["start"].record(stream)
   318       288 7680006117.0    3e+07      4.0              crd_eq_gpu.set_async(crd_eq[:, c * npixc : (c + 1) * npixc], stream=stream)
   319       288 1702070906.0    6e+06      0.9              Isqrt_gpu.set_async(Isqrt[c * npixc : (c + 1) * npixc], stream=stream)
   320       288    4714949.0  16371.4      0.0              event["upload"].record(stream)
   321                                           
   322       288   33074459.0 114841.9      0.0              cublasSetStream(h, stream.handle)
   323                                           
   324                                                       # cublas arrays are in Fortran order, so P=M*N is actually
   325                                                       # peformed as P.T = N.T * M.T
   326       576  310783879.0 539555.3      0.2              cublas_real_mm(  # compute crdtop = dot(eq2top,crd_eq)
   327       288     124826.0    433.4      0.0                  h,
   328       288      68873.0    239.1      0.0                  "n",
   329       288     126244.0    438.3      0.0                  "n",
   330       288     168274.0    584.3      0.0                  npixc,
   331       288     150565.0    522.8      0.0                  3,
   332       288     150982.0    524.2      0.0                  3,
   333       288     103238.0    358.5      0.0                  1.0,
   334       288     541462.0   1880.1      0.0                  crd_eq_gpu.gpudata,
   335       288     110162.0    382.5      0.0                  npixc,
   336       288     231696.0    804.5      0.0                  eq2top_gpu.gpudata,
   337       288     126695.0    439.9      0.0                  3,
   338       288     132011.0    458.4      0.0                  0.0,
   339       288     200696.0    696.9      0.0                  crdtop_gpu.gpudata,
   340       288      59011.0    204.9      0.0                  npixc,
   341                                                       )
   342       288    2494784.0   8662.4      0.0              event["eq2top"].record(stream)
   343                                           
   344       288 8783143151.0    3e+07      4.5              tx, ty, tz = crdtop_gpu.get_async(stream=stream)
   345       288  928854354.0    3e+06      0.5              above_horizon = tz > 0
   346       288 5275984484.0    2e+07      2.7              tx = tx[above_horizon]
   347       288 5265479926.0    2e+07      2.7              ty = ty[above_horizon]
   348       288    1432830.0   4975.1      0.0              nsrcs_up = len(tx)
   349                                           
   350       288     449388.0   1560.4      0.0              if nsrcs_up < 1:
   351                                                           continue
   352                                           
   353       576 4449057001.0    8e+06      2.3              crdtop_lim_gpu = gpuarray.to_gpu_async(
   354       288        3e+10    9e+07     13.6                  crdtop_gpu.get_async(stream=stream)[:, above_horizon].copy(),
   355       288     476581.0   1654.8      0.0                  stream=stream,
   356                                                       )
   357                                           
   358       288  843353690.0    3e+06      0.4              tau_gpu = gpuarray.empty(shape=(nant, nsrcs_up), dtype=real_dtype)
   359                                           
   360       576  193928163.0 336680.8      0.1              cublas_real_mm(  # compute tau = dot(antpos,crdtop) / speed_of_light
   361       288     163686.0    568.4      0.0                  h,
   362       288     220025.0    764.0      0.0                  "n",
   363       288     107980.0    374.9      0.0                  "n",
   364       288     143669.0    498.9      0.0                  nsrcs_up,
   365       288     147727.0    512.9      0.0                  nant,
   366       288     117781.0    409.0      0.0                  3,
   367       288     297607.0   1033.4      0.0                  ONE_OVER_C,
   368       288     241469.0    838.4      0.0                  crdtop_lim_gpu.gpudata,
   369       288     125336.0    435.2      0.0                  nsrcs_up,
   370       288     208407.0    723.6      0.0                  antpos_gpu.gpudata,
   371       288     130155.0    451.9      0.0                  3,
   372       288     225182.0    781.9      0.0                  0.0,
   373       288     105825.0    367.4      0.0                  tau_gpu.gpudata,
   374       288      58780.0    204.1      0.0                  nsrcs_up,
   375                                                       )
   376       288    3951021.0  13718.8      0.0              event["tau"].record(stream)
   377                                           
   378                                                       # Need to do this in polar coordinates, NOT (l,m), at least for
   379                                                       # polarized beams. This is because at zenith, the Efield components are
   380                                                       # discontinuous (in power they are continuous). When interpolating the
   381                                                       # E-field components, you need to treat the zenith point differently
   382                                                       # depending on which "side" of zenith you're on. This is doable in polar
   383                                                       # coordinates, but not in Cartesian coordinates.
   384       576        3e+10    6e+07     17.2              A_gpu = do_beam_interpolation(
   385       288     142503.0    494.8      0.0                  freq,
   386       288     167356.0    581.1      0.0                  beam_list,
   387       288      59572.0    206.8      0.0                  polarized,
   388       288      83695.0    290.6      0.0                  nthreads,
   389       288      82343.0    285.9      0.0                  nax,
   390       288      97372.0    338.1      0.0                  nfeed,
   391       288     144927.0    503.2      0.0                  complex_dtype,
   392       288      86350.0    299.8      0.0                  nbeam,
   393       288      64425.0    223.7      0.0                  use_uvbeam,
   394       288     131294.0    455.9      0.0                  daz,
   395       288     138823.0    482.0      0.0                  dza,
   396       288     160395.0    556.9      0.0                  beam_interp,
   397       288      95895.0    333.0      0.0                  beam_data_gpu,
   398       288      79940.0    277.6      0.0                  event,
   399       288      86303.0    299.7      0.0                  stream,
   400       288     137436.0    477.2      0.0                  tx,
   401       288     111679.0    387.8      0.0                  ty,
   402       288      57730.0    200.5      0.0                  nsrcs_up,
   403                                                       )
   404                                           
   405       576 5354228240.0    9e+06      2.8              v_gpu = gpuarray.empty(
   406       288     868180.0   3014.5      0.0                  shape=(nfeed * nant, nax * nsrcs_up), dtype=complex_dtype
   407                                                       )
   408       576 2420435048.0    4e+06      1.2              Isqrt_lim_gpu = gpuarray.to_gpu_async(
   409       288 7745185913.0    3e+07      4.0                  Isqrt_gpu.get()[above_horizon].copy(), stream=stream
   410                                                       )
   411                                           
   412       288    3484933.0  12100.5      0.0              _logdebug(A_gpu, "Beam")
   413                                           
   414                                                       # compute v = A * sqrtI * exp(1j*tau*freq)
   415                                                       # Ways to block up threads for sending to GPU calculations. "Meas" is for the
   416                                                       # measurement equation function, and "prod" is for the inner-product calculation.
   417       288    6804196.0  23625.7      0.0              block, grid = _get_3d_block_grid(nthreads, nsrcs_up, nant * nax, nfeed)
   418                                           
   419       288     242807.0    843.1      0.0              if t == 0:
   420         2    6258715.0    3e+06      0.0                  logger.info(
   421         1     136085.0 136085.0      0.0                      f"Using {block} = {np.prod(block)} threads in total, in a grid of {grid}, "
   422                                                               "for measurement equation."
   423                                                           )
   424                                           
   425       576   51744123.0  89833.5      0.0              meas_eq(
   426       288      80027.0    277.9      0.0                  A_gpu,
   427       288      70701.0    245.5      0.0                  Isqrt_lim_gpu,
   428       288      95849.0    332.8      0.0                  tau_gpu,
   429       288     116115.0    403.2      0.0                  ang_freq,
   430       288    4063669.0  14110.0      0.0                  np.uint(nsrcs_up),
   431       288     110501.0    383.7      0.0                  beam_idx,
   432       288     123180.0    427.7      0.0                  v_gpu,
   433       288      71152.0    247.1      0.0                  grid=grid,
   434       288      66956.0    232.5      0.0                  block=block,
   435       288      57203.0    198.6      0.0                  stream=stream,
   436                                                       )
   437       288    3332423.0  11570.9      0.0              event["meas_eq"].record(stream)
   438                                           
   439       288     994590.0   3453.4      0.0              _logdebug(v_gpu, "vant")
   440                                           
   441                                                       # compute vis = dot(v, v.T)
   442                                                       # We want to take an outer product over feeds/antennas, contract over
   443                                                       # E-field components, and integrate over the sky.
   444                                                       # Remember cublas is in fortran order...
   445                                                       # v_gpu is (nfeed * nant, nax * nsrcs_up)
   446       576  205729713.0 357169.6      0.1              cublas_complex_mm(
   447       288     116527.0    404.6      0.0                  h,
   448       288      96447.0    334.9      0.0                  "c",  # conjugate transpose for first (remember fortran order)
   449       288      97321.0    337.9      0.0                  "n",  # no transpose for second.
   450       288     110939.0    385.2      0.0                  nfeed * nant,
   451       288      89466.0    310.6      0.0                  nfeed * nant,
   452       288     456283.0   1584.3      0.0                  nax * nsrcs_up,
   453       288      95252.0    330.7      0.0                  1.0,
   454       288     150484.0    522.5      0.0                  v_gpu.gpudata,
   455       288     434487.0   1508.6      0.0                  nax * nsrcs_up,
   456       288      89359.0    310.3      0.0                  v_gpu.gpudata,
   457       288     426253.0   1480.0      0.0                  nax * nsrcs_up,
   458       288      94945.0    329.7      0.0                  0.0,
   459       288     301544.0   1047.0      0.0                  matvis_gpus[c].gpudata,
   460       288      63144.0    219.2      0.0                  nfeed * nant,
   461                                                       )
   462                                           
   463       288    1077487.0   3741.3      0.0              _logdebug(matvis_gpus[c], "Vis")
   464                                           
   465       288    2303467.0   7998.1      0.0              event["vis"].record(stream)
   466                                           
   467       288        8e+10    3e+08     41.5              matvis_gpus[c].get(ary=matvis_cpus[c], stream=stream)
   468       288    6723835.0  23346.6      0.0              event["end"].record(stream)
   469       288    2797871.0   9714.8      0.0          events[nchunks - 1]["end"].synchronize()
   470       288  134131696.0 465735.1      0.1          vis[t] = sum(matvis_cpus)
   471                                           
   472       288     886894.0   3079.5      0.0          if not (t % report_chunk or t == ntimes - 1):
   473        96  872763719.0    9e+06      0.4              plast, mlast = _log_progress(tstart, plast, t + 1, ntimes, pr, mlast)
   474                                           
   475                                               # teardown GPU configuration
   476         1     771818.0 771818.0      0.0      cublasDestroy(h)
   477         1   95447665.0    1e+08      0.0      vis = vis.conj().reshape((ntimes, nfeed, nant, nfeed, nant))
   478         1      15718.0  15718.0      0.0      return vis.transpose((0, 1, 3, 2, 4)) if polarized else vis[:, 0, :, 0, :]

